# 调试和日志说明

## 概述

系统已添加详细的执行日志，帮助排查"发送消息后一直没有结果"的问题。

## 日志位置

所有日志都会输出到控制台（标准输出），包括：

1. **启动日志** - 应用启动和模型加载过程
2. **请求日志** - 每个聊天请求的详细信息
3. **模型推理日志** - 模型生成回复的详细过程
4. **错误日志** - 完整的错误堆栈信息

## 日志格式

### 启动阶段日志

```
============================================================
正在启动应用...
Python 版本: 3.x.x
工作目录: /path/to/project
============================================================
开始加载模型: THUDM/chatglm3-6b
使用设备: cuda/cpu
CUDA 可用: True/False
正在加载分词器...
分词器加载完成，耗时: X.XX 秒
正在加载模型（这可能需要几分钟）...
模型加载完成，耗时: X.XX 秒
模型加载总耗时: X.XX 秒
============================================================
✅ 应用启动完成，模型已加载
============================================================
```

### 请求处理日志

```
============================================================
收到聊天请求 - 时间: 2024-01-01 12:00:00
会话ID: xxxxx-xxxxx-xxxxx
用户消息: 你好
使用思考链路: True
对话历史轮数: 0
开始构建提示词...
已添加思考链路提示
提示词构建完成，长度: XXX 字符
开始生成回复...
模型名称: THUDM/chatglm3-6b
使用设备: cuda
[模型推理] 开始生成回复...
[模型推理] 提示词长度: XXX 字符
[模型推理] 历史对话轮数: 0
[模型推理] 使用 ChatGLM 推理模式
[模型推理] 调用 model.chat()...
[模型推理] ChatGLM 推理完成，耗时: X.XX 秒
[模型推理] 生成回复长度: XXX 字符
回复生成完成，耗时: X.XX 秒
生成回复长度: XXX 字符
回复预览: ...
尝试提取思考过程...
对话历史已保存
请求处理完成，总耗时: X.XX 秒
============================================================
```

### 错误日志

```
============================================================
❌ 启动失败: 错误信息
错误堆栈:
Traceback (most recent call last):
  ...
============================================================
```

## 前端日志

前端在浏览器控制台（F12）中也会输出详细日志：

- `[前端] 检查服务状态...`
- `[前端] 发送消息: ...`
- `[前端] 收到响应，耗时: X.X 秒`
- `[前端] 错误详情: ...`

## 排查步骤

### 1. 检查模型是否加载成功

查看启动日志，确认看到：
```
✅ 应用启动完成，模型已加载
```

如果看到错误，检查：
- 模型名称是否正确
- 网络连接是否正常（首次下载模型需要网络）
- 磁盘空间是否充足
- 内存是否足够

### 2. 检查请求是否到达服务器

发送消息后，查看控制台是否出现：
```
============================================================
收到聊天请求 - 时间: ...
```

如果没有，可能是：
- 前端请求未发送
- 网络连接问题
- 服务器未运行

### 3. 检查模型推理是否开始

查看日志中是否有：
```
[模型推理] 开始生成回复...
[模型推理] 调用 model.chat()...
```

如果卡在这里，可能是：
- 模型推理速度慢（CPU 模式会很慢）
- 内存不足导致卡死
- 模型文件损坏

### 4. 检查推理是否完成

查看日志中是否有：
```
[模型推理] ChatGLM 推理完成，耗时: X.XX 秒
```

如果一直没有这个日志，说明推理过程卡住了。

### 5. 检查前端超时

前端设置了 5 分钟超时。如果超过 5 分钟，会显示超时错误。

## 常见问题

### Q: 日志显示"模型加载失败"

**可能原因：**
- 模型名称错误
- 网络问题（无法下载模型）
- 磁盘空间不足
- 内存不足

**解决方法：**
- 检查 `config.py` 中的模型名称
- 检查网络连接
- 检查磁盘和内存空间

### Q: 日志显示请求已收到，但推理一直不完成

**可能原因：**
- CPU 模式推理很慢（可能需要几分钟）
- 内存不足导致卡死
- 模型文件问题

**解决方法：**
- 使用 GPU 加速（如果有）
- 检查内存使用情况
- 尝试使用更小的模型

### Q: 前端显示超时错误

**可能原因：**
- 模型推理时间超过 5 分钟
- 服务器卡死

**解决方法：**
- 查看服务器日志确认推理是否在进行
- 如果推理很慢，可以增加前端超时时间
- 检查服务器资源使用情况

### Q: 前端显示"无法连接到服务器"

**可能原因：**
- 服务器未运行
- 端口被占用
- 防火墙阻止

**解决方法：**
- 确认服务器正在运行
- 检查端口是否正确
- 检查防火墙设置

## 性能优化建议

1. **使用 GPU**：如果有 GPU，确保 CUDA 可用，推理速度会快很多
2. **使用量化模型**：如果内存不足，可以使用量化版本的模型
3. **调整生成参数**：在 `config.py` 中调整 `GENERATION_CONFIG`，减少 `max_new_tokens` 可以加快生成速度
4. **使用更小的模型**：如果速度太慢，可以尝试更小的模型（如 ChatGLM2-6B）

## 日志级别

当前日志级别设置为 `INFO`，会显示所有重要信息。如果需要更详细的调试信息，可以在代码中将日志级别改为 `DEBUG`。

